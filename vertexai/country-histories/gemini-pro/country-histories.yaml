# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# [START workflows_vertexai_gemini_text]
main:
    params: [args]
    steps:
    - init:
        assign:
            - project: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
            - location: "us-central1"
            - model: "gemini-pro"
            - method: "streamGenerateContent"
            - llm_api_endpoint: ${"https://" + location + "-aiplatform.googleapis.com" + "/v1/projects/" + project + "/locations/" + location + "/publishers/google/models/" + model + ":" + method}
            - histories: {}
    - loop_over_countries:
        parallel:
            shared: [histories]
            for:
                value: country
                in: ${args.countries}
                steps:
                    - ask_llm:
                        call: http.post
                        args:
                            url: ${llm_api_endpoint}
                            auth:
                                type: OAuth2
                            body:
                                contents:
                                    role: "USER"
                                    parts:
                                        text: ${"Can you tell me about the history of " + country}
                                generation_config:
                                    temperature: 0.5
                                    max_output_tokens: 2048
                                    top_p: 0.8
                                    top_k: 40
                        result: llm_response
                    - init_history:
                        assign:
                            - history: ""
                    - extract_text_from_each_element:
                        for:
                            value: element
                            in: ${llm_response.body}
                            steps:
                            - extract_text:
                                assign:
                                    - text: ${element.candidates[0].content.parts[0].text}
                            - combine_text:
                                assign:
                                    - history: ${history + text}
                    - add_to_histories:
                        assign:
                            - histories[country]: ${history}
    - return_result:
        return: ${histories}
# [END workflows_vertexai_gemini_text]
