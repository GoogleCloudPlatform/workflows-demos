# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This workflow shows how to find capitals of a list of countries
# by calling Vertex AI's text-bison model in parallel for each country.
main:
    params: [args]
    steps:
    - init:
        assign:
            - api_endpoint: "us-central1-aiplatform.googleapis.com"
            - project_id: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
            - model_id: "text-bison"
            - location_id: "us-central1"
            # - countries: ["Argentina", "Brazil", "Cyprus", "Denmark", "England",
            # "Finland", "Greece", "Honduras", "Italy", "Japan", "Korea",
            # "Latvia", "Morocco", "Nepal", "Oman"]
            - countries: ${args.countries}
            - histories: {}
    - loop_over_countries:
        parallel:
            shared: [histories]
            for:
                value: country
                in: ${countries}
                steps:
                    - ask_llm:
                        call: http.post
                        args:
                            url: ${"https://" + api_endpoint + "/v1/projects/" + project_id + "/locations/" + location_id + "/publishers/google/models/" + model_id + ":predict"}
                            auth:
                                type: OAuth2
                            body:
                                instances:
                                    - prompt: '${"Can you  tell me about the
                                    history of " + country}'
                                parameters:
                                    temperature: 0.5
                                    maxOutputTokens: 2048
                                    topP: 0.8
                                    topK: 40
                        result: llm_response
                    - add_to_histories:
                        assign:
                            - history: ${llm_response.body.predictions[0].content}
                            # Get rid of the extra space at the beginning of content
                            - history: ${text.substring(history, 1, len(history))}
                            - country_to_history: ${country + ":" + history}
                            - histories[country]: ${history}
    - return_result:
        return: ${histories}